{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b982a2c9-07d1-486d-907e-dcda66999475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import json\n",
    "import random\n",
    "random.seed = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4af4497-1b5c-44e4-9a73-7e430b47dbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '人类指令（必填）',\n",
       " 'input': '人类输入（选填）',\n",
       " 'output': '模型回答（必填）',\n",
       " 'system': '系统提示词（选填）',\n",
       " 'history': [['第一轮指令（选填）', '第一轮回答（选填）'], ['第二轮指令（选填）', '第二轮回答（选填）']]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"instruction\": \"人类指令（必填）\",\n",
    "    \"input\": \"人类输入（选填）\",\n",
    "    \"output\": \"模型回答（必填）\",\n",
    "    \"system\": \"系统提示词（选填）\",\n",
    "    \"history\": [\n",
    "      [\"第一轮指令（选填）\", \"第一轮回答（选填）\"],\n",
    "      [\"第二轮指令（选填）\", \"第二轮回答（选填）\"]\n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e431787-d5a8-438a-a247-8a63de219652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b88f36-8e20-46af-93b0-3b4a5f9e7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_alpaca_format(input_folder, output_file):\n",
    "    \"\"\"\n",
    "    Converts all JSON files in a folder to Alpaca format and saves them as a JSONL file.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing JSON files.\n",
    "        output_file (str): Path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    alpaca_data = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing files\"):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            # Read the JSON file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "\n",
    "                    # Extract fields and convert to Alpaca format\n",
    "                    instruction = data.get(\"message_1\", \"\")\n",
    "                    output = data.get(\"message_2\", \"\")\n",
    "\n",
    "                    # Add to the list if both fields are present\n",
    "                    if instruction and output:\n",
    "                        alpaca_data.append({\n",
    "                            \"instruction\": instruction,\n",
    "                            \"input\": \"\",\n",
    "                            \"output\": output\n",
    "                        })\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "\n",
    "    # Write all data to the output JSONL file\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "        for entry in alpaca_data:\n",
    "            out_file.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"Conversion complete. {len(alpaca_data)} items saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8aaee0-b38c-45dd-962b-91f7debb0ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20004/20004 [01:23<00:00, 240.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. 20000 items saved to physics-200003.jsonl.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_folder = \"/root/a100_nas_lvbo/peixunban/002754_lvbo/SFT/00_dataset/physics\"\n",
    "output_file = \"physics-200003.jsonl\"\n",
    "convert_to_alpaca_format(input_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a72783-467a-4f90-8481-4b59a07ed2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b8833-4841-440c-9250-47533a0c3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_parquet_to_alpaca_format(input_parquet, output_file):\n",
    "    \"\"\"\n",
    "    Converts a Parquet file with columns 'question' and 'answer' to Alpaca format and saves it as a JSONL file.\n",
    "\n",
    "    Args:\n",
    "        input_parquet (str): Path to the Parquet file.\n",
    "        output_file (str): Path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    alpaca_data = []\n",
    "\n",
    "    # Read the Parquet file\n",
    "    try:\n",
    "        df = pd.read_parquet(input_parquet)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Parquet file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Iterate through rows and convert to Alpaca format\n",
    "    for _, row in tqdm(df.iterrows(), desc=\"Processing rows\", total=len(df)):\n",
    "        instruction = row.get(\"question\", \"\")\n",
    "        output = row.get(\"answer\", \"\")\n",
    "\n",
    "        if instruction and output:\n",
    "            alpaca_data.append({\n",
    "                \"instruction\": instruction,\n",
    "                \"input\": \"\",\n",
    "                \"output\": output\n",
    "            })\n",
    "\n",
    "    # Write all data to the output JSONL file\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "        for entry in alpaca_data:\n",
    "            out_file.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"Conversion complete. {len(alpaca_data)} items saved to {output_file}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6f72c-2673-425d-b59e-2ac1571e5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_parquet = \"/root/a100_nas_lvbo/peixunban/002754_lvbo/SFT/00_dataset/physics-arxiv/data/train-00000-of-00001-5bba4a271402bdbb.parquet\"\n",
    "output_file = \"physics-arxiv.jsonl\"\n",
    "convert_parquet_to_alpaca_format(input_parquet, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
